{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgoR9JB14rT99kuzXCbVow",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dusarp/dance-bits-experiments/blob/main/spectrogram_dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "FXacaK_7EkNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSIdbiNSEeS6"
      },
      "outputs": [],
      "source": [
        "class MelSpectrogramDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.file_list = [f for f in os.listdir(data_dir) if f.endswith('.npy')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = os.path.join(self.data_dir, self.file_list[idx])\n",
        "        mel_spectrogram = np.load(file_path)\n",
        "\n",
        "        # Convert to torch tensor and add channel dimension\n",
        "        mel_spectrogram = torch.from_numpy(mel_spectrogram).float().unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            mel_spectrogram = self.transform(mel_spectrogram)\n",
        "\n",
        "        # For this example, we'll use random labels. Replace this with your actual labels.\n",
        "        label = torch.randint(0, 10, (1,)).item()\n",
        "\n",
        "        return mel_spectrogram, label\n",
        "\n",
        "# Define any transformations you want to apply to your data\n",
        "transform = transforms.Compose([\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# Create the dataset\n",
        "dataset = MelSpectrogramDataset(data_dir='path/to/your/npy/files', transform=transform)\n",
        "\n",
        "# Create the data loader\n",
        "batch_size = 32\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "# Example usage in a training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_mels, batch_labels in data_loader:\n",
        "        # Your training code here\n",
        "        # batch_mels shape: (batch_size, 1, mel_freq_bins, time_steps)\n",
        "        # batch_labels shape: (batch_size,)\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a breakdown of the code:\n",
        "\n",
        "1. We define a custom `MelSpectrogramDataset` class that inherits from `torch.utils.data.Dataset`.\n",
        "\n",
        "2. The `__init__` method initializes the dataset with the directory containing the .npy files and any transformations to be applied.\n",
        "\n",
        "3. `__len__` returns the total number of samples in the dataset.\n",
        "\n",
        "4. `__getitem__` loads a single mel spectrogram from a .npy file, converts it to a PyTorch tensor, adds a channel dimension, applies any transformations, and returns the mel spectrogram along with a label.\n",
        "\n",
        "5. We create an instance of the dataset with a specified directory and transformations.\n",
        "\n",
        "6. We create a `DataLoader` that will handle batching, shuffling, and parallel data loading.\n",
        "\n",
        "7. In the example usage section, we show how you might use this data loader in a training loop.\n",
        "\n",
        "To use this data loader with your CNN:\n",
        "\n",
        "1. Replace `'path/to/your/npy/files'` with the actual path to your directory containing the .npy files.\n",
        "\n",
        "2. Modify the label generation in `__getitem__` to use your actual labels instead of random ones.\n",
        "\n",
        "3. Adjust the `batch_size`, `num_workers`, and other parameters of the `DataLoader` as needed for your specific use case.\n",
        "\n",
        "4. Use the `data_loader` in your training loop to feed batches of mel spectrograms and labels to your CNN.\n",
        "\n",
        "This data loader will efficiently load your mel spectrograms from .npy files and prepare them for training your convolutional neural network."
      ],
      "metadata": {
        "id": "kIJGh7IwEmGr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "psB_QvCXEvW-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}